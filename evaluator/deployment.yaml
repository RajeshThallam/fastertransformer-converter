apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-tmp-model
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 200Gi
  storageClassName: standard-rwo
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: triton-server-deployment
  labels:
    app: triton-server
    version: v1 
spec:
  replicas: 1
  selector:
    matchLabels:
      app: triton-server 
      version: v1
  template:
    metadata:
      labels:
        app: triton-server
        version: v1
    spec:
      serviceAccountName: triton-sa
      volumes:
        - name: pvc-tmp-vol
          persistentVolumeClaim:
            claimName: pvc-tmp-model
      nodeSelector:
        cloud.google.com/gke-accelerator: nvidia-tesla-a100
      containers:
        - name: triton-inference-server 
          image: gcr.io/rl-llm-dev/bignlp-inference:latest
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              nvidia.com/gpu: 1
          args: ["tritonserver", "--model-store=gs://rl-llm-models/ul2-xsum-ft", "--log-error=1", "--log-verbose=99", "--log-info=1", "--log-warning=1"]
          volumeMounts:
          - mountPath: "/tmp"
            name: pvc-tmp-vol
          ports:
            - containerPort: 8000
              name: http
            - containerPort: 8001
              name: grpc
            - containerPort: 8002
              name: metrics
          livenessProbe:
            failureThreshold: 60
            initialDelaySeconds: 1800
            periodSeconds: 5
            httpGet:
              path: /v2/health/live
              port: http
          readinessProbe:
            failureThreshold: 60
            initialDelaySeconds: 1800
            periodSeconds: 5
            httpGet:
              path: /v2/health/ready
              port: http
      securityContext:
        runAsUser: 1000
        fsGroup: 1000